dtrain <- xgb.DMatrix(x_train,label=train1_y,missing=NA)
dtest <- xgb.DMatrix(x_test,label=test_y,missing=NA)
#Define XGboost model and parameters
param <- list(  objective           = "reg:linear",
gamma               =0.1,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.1,
max_depth           = 5,
min_child_weight    = 20,
subsample           = .9,
colsample_bytree    = .9,
tree_method = 'hist'
)
#Add the watchlist
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[best_ntrees,]$test-rmse
train_param$test_error<-test_error
test_error<-as.numeric(unclass(XGB_model)$evaluation_log[best_ntrees,]$test-rmse)
test_error<-unclass(XGB_model)$evaluation_log[best_ntrees,]$as.numeric(test_rmse_mean)
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse_mean
train_param$test_error<-test_error
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse_mean
library(data.table)
library(Metrics)
library(caret)
library(xgboost)
library(ggplot2)
#read in data
train<-fread("./project/volume/data/processed/train(roll4).csv")
sample_pos<-"WR"
train<-train[Pos== sample_pos]
#Create Multiple Training and Testing Sets
train1<-train[season<2019]
test1<-train[season==2019]
#Prep Data for Modeling
train1_y<-train1$PPRFantasyPoints
test_y<-test1$PPRFantasyPoints
test1$PPRFantasyPoints<-0
#Get rid of columns not needed for modeling
drops<-c("season","Tm","game_id","Opponent","Player","Pos","cumulativeweek")
train1<-train1[, !drops, with = FALSE]
test1<-test1[, !drops, with = FALSE]
#Need to keep position in as a variable and create dummies for this purpose
dummies<-dummyVars(PPRFantasyPoints~., data=train1)
x_train<-predict(dummies, newdata = train1)
x_test<-predict(dummies, newdata = test1)
#Create proper representation of data for modeling
dtrain <- xgb.DMatrix(x_train,label=train1_y,missing=NA)
dtest <- xgb.DMatrix(x_test,label=test_y,missing=NA)
#Define XGboost model and parameters
param <- list(  objective           = "reg:linear",
gamma               =0.1,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.1,
max_depth           = 5,
min_child_weight    = 20,
subsample           = .9,
colsample_bytree    = .9,
tree_method = 'hist'
)
#Add the watchlist
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse_mean
train_param$test_error<-test_error
library(data.table)
library(Metrics)
library(caret)
library(xgboost)
library(ggplot2)
#read in data
train<-fread("./project/volume/data/processed/train(roll4).csv")
sample_pos<-"WR"
train<-train[Pos== sample_pos]
#Create Multiple Training and Testing Sets
train1<-train[season<2019]
test1<-train[season==2019]
#Prep Data for Modeling
train1_y<-train1$PPRFantasyPoints
test_y<-test1$PPRFantasyPoints
test1$PPRFantasyPoints<-0
#Get rid of columns not needed for modeling
drops<-c("season","Tm","game_id","Opponent","Player","Pos","cumulativeweek")
train1<-train1[, !drops, with = FALSE]
test1<-test1[, !drops, with = FALSE]
#Need to keep position in as a variable and create dummies for this purpose
dummies<-dummyVars(PPRFantasyPoints~., data=train1)
x_train<-predict(dummies, newdata = train1)
x_test<-predict(dummies, newdata = test1)
#Create proper representation of data for modeling
dtrain <- xgb.DMatrix(x_train,label=train1_y,missing=NA)
dtest <- xgb.DMatrix(x_test,label=test_y,missing=NA)
#Define XGboost model and parameters
param <- list(  objective           = "reg:linear",
gamma               =0.1,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.1,
max_depth           = 5,
min_child_weight    = 20,
subsample           = .9,
colsample_bytree    = .9,
tree_method = 'hist'
)
#Add the watchlist
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test-rmse
train_param$test_error<-test_error
library(data.table)
library(Metrics)
library(caret)
library(xgboost)
library(ggplot2)
#read in data
train<-fread("./project/volume/data/processed/train(roll4).csv")
sample_pos<-"WR"
train<-train[Pos== sample_pos]
#Create Multiple Training and Testing Sets
train1<-train[season<2019]
test1<-train[season==2019]
#Prep Data for Modeling
train1_y<-train1$PPRFantasyPoints
test_y<-test1$PPRFantasyPoints
test1$PPRFantasyPoints<-0
#Get rid of columns not needed for modeling
drops<-c("season","Tm","game_id","Opponent","Player","Pos","cumulativeweek")
train1<-train1[, !drops, with = FALSE]
test1<-test1[, !drops, with = FALSE]
#Need to keep position in as a variable and create dummies for this purpose
dummies<-dummyVars(PPRFantasyPoints~., data=train1)
x_train<-predict(dummies, newdata = train1)
x_test<-predict(dummies, newdata = test1)
#Create proper representation of data for modeling
dtrain <- xgb.DMatrix(x_train,label=train1_y,missing=NA)
dtest <- xgb.DMatrix(x_test,label=test_y,missing=NA)
#Define XGboost model and parameters
param <- list(  objective           = "reg:linear",
gamma               =0.1,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.1,
max_depth           = 5,
min_child_weight    = 20,
subsample           = .9,
colsample_bytree    = .9,
tree_method = 'hist'
)
#Add the watchlist
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse
train_param$test_error<-test_error
View(train_param)
library(data.table)
library(Metrics)
library(caret)
library(xgboost)
library(ggplot2)
#read in data
train<-fread("./project/volume/data/processed/train(roll4).csv")
sample_pos<-"WR"
train<-train[Pos== sample_pos]
#Create Multiple Training and Testing Sets
train1<-train[season<2019]
test1<-train[season==2019]
#Prep Data for Modeling
train1_y<-train1$PPRFantasyPoints
test_y<-test1$PPRFantasyPoints
test1$PPRFantasyPoints<-0
#Get rid of columns not needed for modeling
drops<-c("season","Tm","game_id","Opponent","Player","Pos","cumulativeweek")
train1<-train1[, !drops, with = FALSE]
test1<-test1[, !drops, with = FALSE]
#Need to keep position in as a variable and create dummies for this purpose
dummies<-dummyVars(PPRFantasyPoints~., data=train1)
x_train<-predict(dummies, newdata = train1)
x_test<-predict(dummies, newdata = test1)
#Create proper representation of data for modeling
dtrain <- xgb.DMatrix(x_train,label=train1_y,missing=NA)
dtest <- xgb.DMatrix(x_test,label=test_y,missing=NA)
#Define XGboost model and parameters
param <- list(  objective           = "reg:linear",
gamma               =0.001,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.001,
max_depth           = 20,
min_child_weight    = 1,
subsample           = 1,
colsample_bytree    = 1,
tree_method = 'hist'
)
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse
train_param$test_error<-test_error
View(train_param)
fwrite(train_param, "./project/src/models/trainingHyperparameters(roll4).csv", append = T)
param <- list(  objective           = "reg:linear",
gamma               =0.01,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.01,
max_depth           = 10,
min_child_weight    = 5,
subsample           = .99,
colsample_bytree    = .95,
tree_method = 'hist'
)
#Add the watchlist
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse
train_param$test_error<-test_error
fwrite(train_param, "./project/src/models/trainingHyperparameters(roll4).csv", append = T)
param <- list(  objective           = "reg:linear",
gamma               =0.05,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.05,
max_depth           = 5,
min_child_weight    = 10,
subsample           = .95,
colsample_bytree    = .95,
tree_method = 'hist'
)
#Add the watchlist
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse
train_param$test_error<-test_error
fwrite(train_param, "./project/src/models/trainingHyperparameters(roll4).csv", append = T)
param <- list(  objective           = "reg:linear",
gamma               =0.1,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.1,
max_depth           = 2,
min_child_weight    = 25,
subsample           = .9,
colsample_bytree    = .9,
tree_method = 'hist'
)
#Add the watchlist
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse
train_param$test_error<-test_error
fwrite(train_param, "./project/src/models/trainingHyperparameters(roll4).csv", append = T)
param <- list(  objective           = "reg:linear",
gamma               =0.1,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.1,
max_depth           = 5,
min_child_weight    = 25,
subsample           = .9,
colsample_bytree    = .9,
tree_method = 'hist'
)
#Add the watchlist
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse
train_param$test_error<-test_error
fwrite(train_param, "./project/src/models/trainingHyperparameters(roll4).csv", append = T)
param <- list(  objective           = "reg:linear",
gamma               =0.2,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.2,
max_depth           = 2,
min_child_weight    = 50,
subsample           = .8,
colsample_bytree    = .8,
tree_method = 'hist'
)
#Add the watchlist
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse
train_param$test_error<-test_error
fwrite(train_param, "./project/src/models/trainingHyperparameters(roll4).csv", append = T)
param <- list(  objective           = "reg:linear",
gamma               =0.1,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.1,
max_depth           = 2,
min_child_weight    = 20,
subsample           = .95,
colsample_bytree    = .95,
tree_method = 'hist'
)
#Add the watchlist
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse
train_param$test_error<-test_error
fwrite(train_param, "./project/src/models/trainingHyperparameters(roll4).csv", append = T)
param <- list(  objective           = "reg:linear",
gamma               =0.1,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.1,
max_depth           = 2,
min_child_weight    = 25,
subsample           = .95,
colsample_bytree    = .95,
tree_method = 'hist'
)
#Add the watchlist
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse
train_param$test_error<-test_error
fwrite(train_param, "./project/src/models/trainingHyperparameters(roll4).csv", append = T)
library(data.table)
library(Metrics)
library(caret)
library(xgboost)
library(ggplot2)
#read in data
train<-fread("./project/volume/data/processed/train(roll3).csv")
sample_pos<-"WR"
train<-train[Pos== sample_pos]
train<-fread("./project/volume/data/processed/train(roll3).csv")
sample_pos<-"WR"
train<-train[Pos== sample_pos]
#Create Multiple Training and Testing Sets
train1<-train[season<2019]
test1<-train[season==2019]
#Prep Data for Modeling
train1_y<-train1$PPRFantasyPoints
test_y<-test1$PPRFantasyPoints
test1$PPRFantasyPoints<-0
#Get rid of columns not needed for modeling
drops<-c("season","Tm","game_id","Opponent","Player","Pos","cumulativeweek")
train1<-train1[, !drops, with = FALSE]
test1<-test1[, !drops, with = FALSE]
#Need to keep position in as a variable and create dummies for this purpose
dummies<-dummyVars(PPRFantasyPoints~., data=train1)
x_train<-predict(dummies, newdata = train1)
x_test<-predict(dummies, newdata = test1)
#Create proper representation of data for modeling
dtrain <- xgb.DMatrix(x_train,label=train1_y,missing=NA)
dtest <- xgb.DMatrix(x_test,label=test_y,missing=NA)
param <- list(  objective           = "reg:linear",
gamma               =0.001,
booster             = "gbtree",
eval_metric         = "rmse",
eta                 = 0.001,
max_depth           = 20,
min_child_weight    = 1,
subsample           = 1,
colsample_bytree    = 1,
tree_method = 'hist'
)
#Add the watchlist
watchlist <- list(train = dtrain, test = dtest)
null_y<-mean(train1_y)
rmse(test_y,null_y)
rollingfantasypoint_y<-test1$Player_roll_4_PPRFantasyPoints/4
rollingfantasypoint_y[is.na(rollingfantasypoint_y)]<-null_y
rmse(test_y, rollingfantasypoint_y)
#Create Predictions
XGB_model<-xgb.train(params=param,nrounds=10000,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=1,nthread=4,
early_stopping_rounds=25)
#Write out hyperparameters so they can be compared
best_ntrees<-unclass(XGB_model)$best_iteration
train_param<-data.table(t(param))
train_param$best_ntrees<-best_ntrees
test_error<-unclass(XGB_model)$evaluation_log[as.numeric(best_ntrees),]$test_rmse
train_param$test_error<-test_error
#fwrite(train_param, "./project/src/models/trainingHyperparameters(roll4).csv", append = T)
fwrite(train_param, "./project/src/models/trainingHyperparameters(roll3).csv", append = T)
