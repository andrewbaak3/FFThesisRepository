}
#Set the start web url
footballDB<-read_html("https://www.footballdb.com/transactions/injuries.html")
# Set start web url
NFL <- read_html("https://www.nfl.com/stats/player-stats/")
length(@)
length(2)
seasons<-c("2016", "2017", "2020")
length(seasons)
#Set the start web url
path1<-("https://www.footballdb.com/transactions/injuries.html")
#Set the start web url
path1<-("https://www.footballdb.com/transactions/injuries.html?yr=")
#this function is useful for grabbing all links on a page
links <- function(URL)
{
getLinks <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "href"))
node
},
links = function() links)
}
h1 <- getLinks()
htmlTreeParse(URL, handlers = h1)
h1$links()
}
#function to return name of players
get_name<-function(url){
page<-read_html(url)
node<-html_nodes(page,".player-name")
player_name<-html_text(node)
player_name
}
#Set the start web url
path1<-("https://www.footballdb.com/transactions/injuries.html?yr=")
seasons<-c("2016", "2017", "2020")
i<-1
path2<-paste0(path1,seasons[i])
path2
J<-1
j<-1
for (j in 1:17) {
path3<-paste0(path2,"&wk=",j,"&type=reg")
}
path3
weeks<-1:17
library(rvest)
library(XML)
library(data.table)
#this function is useful for grabbing all links on a page
links <- function(URL)
{
getLinks <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "href"))
node
},
links = function() links)
}
h1 <- getLinks()
htmlTreeParse(URL, handlers = h1)
h1$links()
}
#function to return name of players
get_name<-function(url){
page<-read_html(url)
node<-html_nodes(page,".player-name")
player_name<-html_text(node)
player_name
}
#Set the start web url
path1<-("https://www.footballdb.com/transactions/injuries.html?yr=")
seasons<-c("2016", "2017", "2020")
weeks<-1:17
i<-1
path2<-paste0(path1,seasons[i])
path2
j<-1
path3<-paste0(path2,"&wk=",j,"&type=reg")
path3
tables<-html_table(read_html(path3),fill = TRUE)
View(tables)
tables<-html_table(read_html(path3),fill = TRUE)
page<-read_html("https://www.footballdb.com/transactions/injuries.html")
currentpages<-links(page)
currentpages
next_page<-currentpages[grep("/transactions/injuries.html?yr",currentpages)]
next_page
next_page<-currentpages[grep("?yr=",currentpages)]
next_page
library(rvest)
library(XML)
library(data.table)
#this function is useful for grabbing all links on a page
links <- function(URL)
{
getLinks <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "href"))
node
},
links = function() links)
}
h1 <- getLinks()
htmlTreeParse(URL, handlers = h1)
h1$links()
}
#function to return name of players
get_name<-function(url){
page<-read_html(url)
node<-html_nodes(page,".player-name")
player_name<-html_text(node)
player_name
}
#Set the start web url
path1<-("https://www.footballdb.com/transactions/injuries.html?yr=")
seasons<-c("2016", "2017", "2020")
weeks<-1:17
data<-NULL
i<-1
path2<-paste0(path1,seasons[i])
path2
j<-1
path3<-paste0(path2,"&wk=",j,"&type=reg")
path3
URL<-read_html(path3)
tables<-html_table(URL,fill = TRUE)
tables<-html_nodes(URL, "divtable divtable-striped divtable-mobile")
#Set the start web url
path1<-("https://www.footballdb.com/transactions/injuries.html?yr=")
seasons<-c("2016", "2017", "2020")
weeks<-1:17
data<-NULL
i<-1
path2<-paste0(path1,seasons[i])
path2
j<-1
path3<-paste0(path2,"&wk=",j,"&type=reg")
path3
URL<-read_html(path3)
tables<-html_nodes(URL, "divtable divtable-striped divtable-mobile")
View(tables)
tables<-html_nodes(URL, "tr")
URL<-read_html(path3)
tables<-html_nodes(URL, "tr")
tables<-html_nodes(URL, ".divtable")
View(tables)
tables<-data.table(tables)
View(tables)
tables<-html_nodes(URL, ".divtable")
tables[i]
tables[2]
table<-data.table(tables[1])
View(table)
tables<-data.table(html_nodes(URL, ".divtable"))
View(table)
View(tables)
tables<-data.table(html_nodes(URL, ".divtable"))
divtables<-html_nodes(URL, ".divtable")
View(divtables)
divtables[[2]]
divtables[[1]]
divtables[[2]][1]
divtables[[2]][[1]]
divtables[[2]][[3]]
divtables[[2]][[2]]
divtables[[2]]$Injury
table<-data.table(divtables[[1]])
View(table)
html_table(divtable[[1]])
html_table(divtables[[1]])
library(rvest)
library(XML)
library(data.table)
# this function is useful for grabing all links on a page
links <- function(URL)
{
getLinks <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "href"))
node
},
links = function() links)
}
h1 <- getLinks()
htmlTreeParse(URL, handlers = h1)
h1$links()
}
# this function gets a single value from a page (player name in this case)
get_name<-function(url){
page<-read_html(url)
node<-html_nodes(page,".player-name")
player_name<-html_text(node)
player_name
}
# Set start web url
NFL <- read_html("https://www.nfl.com/stats/player-stats/")
Player_lst<-NULL
current_page_links<-links(NFL)
current_page_links
next_page_link<-current_page_links[grep("/stats/player-stats/category",current_page_links)]
next_page_link
next_page_link<-next_page_link[grep("?aftercursor",next_page_link)]
next_page_link
next_page_link<-gsub("/stats/player-stats/","",next_page_link)
next_page_link
while (length(next_page_link)>0){
player_link_lst<-current_page_links[grep("/players/",current_page_links)]
player_link_lst<-player_link_lst[-grep("www.nfl",player_link_lst)]
Player_lst<-c(Player_lst,player_link_lst)
current_page<-read_html(paste0("https://www.nfl.com/stats/player-stats/",next_page_link))
current_page_links<-links(current_page)
next_page_link<-current_page_links[grep("/stats/player-stats/category",current_page_links)]
next_page_link<-next_page_link[grep("?aftercursor",next_page_link)]
next_page_link<-gsub("/stats/player-stats/","",next_page_link)
}
player_link_lst<-current_page_links[grep("/players/",current_page_links)]
player_link_lst
library(rvest)
library(XML)
library(data.table)
#this function is useful for grabbing all links on a page
links <- function(URL)
{
getLinks <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "href"))
node
},
links = function() links)
}
h1 <- getLinks()
htmlTreeParse(URL, handlers = h1)
h1$links()
}
#function to return name of players
get_name<-function(url){
page<-read_html(url)
node<-html_nodes(page,".player-name")
player_name<-html_text(node)
player_name
}
#Set the start web url
path1<-("https://www.footballdb.com/transactions/injuries.html?yr=")
seasons<-c("2016", "2017", "2020")
weeks<-1:17
weeks[1]
seasons[1]
seasons[-1]
seasons[1]
data<-NULL
i<-2
i<-1
path2<-paste0(path1,seasons[i])
path2
j<-1
path3<-paste0(path2,"&wk=",j,"&type=reg")
path3
URL<-read_html(path3)
divtables<-html_nodes(URL, ".divtable")
divtables
divtables[[2]]
divtables[[1]]
dog<-divtables[[1]]
dog
View(dog)
dog<-html_text(dog)
dog
divtables[1]
divtables[2]
cat<-divtables[2]
cat
cat<-html_text(cat)
cat
length(divtables)
start<-"https://www.footballdb.com/transactions/injuries.html"
current<-links(start)
current
links <- function(URL)
{
getLinks <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "href"))
node
},
links = function() links)
}
h1 <- getLinks()
htmlTreeParse(URL, handlers = h1)
h1$links()
}
start<-"https://www.footballdb.com/transactions/injuries.html"
current<-links(start)
start<-"https://www.footballdb.com/transactions/injuries.html?yr="
current<-links(start)
current
start<-read_html("https://www.footballdb.com/transactions/injuries.html")
current<-links(start)
current
nextlink<-current[grep("?yr=",current)]
nextlink
nextlink<-nextlink[-grep("/standings/",nextlink)]
nextlink<-nextlink[-grep("/draft/",nextlink)]
nextlink<-nextlink[-grep("/scores/",nextlink)]
nextlink
while (length(next_page_link)>0){
player_link_lst<-current_page_links[grep("/players/",current_page_links)]
player_link_lst<-player_link_lst[-grep("www.nfl",player_link_lst)]
Player_lst<-c(Player_lst,player_link_lst)
current_page<-read_html(paste0("https://www.nfl.com/stats/player-stats/",next_page_link))
current_page_links<-links(current_page)
next_page_link<-current_page_links[grep("/stats/player-stats/category",current_page_links)]
next_page_link<-next_page_link[grep("?aftercursor",next_page_link)]
next_page_link<-gsub("/stats/player-stats/","",next_page_link)
}
Player_lst<-NULL
current_page_links<-links(NFL)
next_page_link<-current_page_links[grep("/stats/player-stats/category",current_page_links)]
next_page_link<-next_page_link[grep("?aftercursor",next_page_link)]
next_page_link<-gsub("/stats/player-stats/","",next_page_link)
while (length(next_page_link)>0){
player_link_lst<-current_page_links[grep("/players/",current_page_links)]
player_link_lst<-player_link_lst[-grep("www.nfl",player_link_lst)]
Player_lst<-c(Player_lst,player_link_lst)
current_page<-read_html(paste0("https://www.nfl.com/stats/player-stats/",next_page_link))
current_page_links<-links(current_page)
next_page_link<-current_page_links[grep("/stats/player-stats/category",current_page_links)]
next_page_link<-next_page_link[grep("?aftercursor",next_page_link)]
next_page_link<-gsub("/stats/player-stats/","",next_page_link)
}
library(rvest)
library(XML)
library(data.table)
# this function is useful for grabing all links on a page
links <- function(URL)
{
getLinks <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "href"))
node
},
links = function() links)
}
h1 <- getLinks()
htmlTreeParse(URL, handlers = h1)
h1$links()
}
# this function gets a single value from a page (player name in this case)
get_name<-function(url){
page<-read_html(url)
node<-html_nodes(page,".player-name")
player_name<-html_text(node)
player_name
}
library(rvest)
library(XML)
library(data.table)
# this function is useful for grabing all links on a page
links <- function(URL)
{
getLinks <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "href"))
node
},
links = function() links)
}
h1 <- getLinks()
htmlTreeParse(URL, handlers = h1)
h1$links()
}
# this function gets a single value from a page (player name in this case)
get_name<-function(url){
page<-read_html(url)
node<-html_nodes(page,".player-name")
player_name<-html_text(node)
player_name
}
NFL <- read_html("https://www.nfl.com/stats/player-stats/")
# get all the players names
Player_lst<-NULL
current_page_links<-links(NFL)
next_page_link<-current_page_links[grep("/stats/player-stats/category",current_page_links)]
next_page_link<-next_page_link[grep("?aftercursor",next_page_link)]
next_page_link<-gsub("/stats/player-stats/","",next_page_link)
current_page_links
next_page_link
while (length(next_page_link)>0){
player_link_lst<-current_page_links[grep("/players/",current_page_links)]
player_link_lst<-player_link_lst[-grep("www.nfl",player_link_lst)]
Player_lst<-c(Player_lst,player_link_lst)
current_page<-read_html(paste0("https://www.nfl.com/stats/player-stats/",next_page_link))
current_page_links<-links(current_page)
next_page_link<-current_page_links[grep("/stats/player-stats/category",current_page_links)]
next_page_link<-next_page_link[grep("?aftercursor",next_page_link)]
next_page_link<-gsub("/stats/player-stats/","",next_page_link)
}
Player_lst
#this function is useful for grabbing all links on a page
links <- function(URL)
{
getLinks <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "href"))
node
},
links = function() links)
}
h1 <- getLinks()
htmlTreeParse(URL, handlers = h1)
h1$links()
}
#function to return name of players
get_name<-function(url){
page<-read_html(url)
node<-html_nodes(page,".player-name")
player_name<-html_text(node)
player_name
}
start<-read_html("https://www.footballdb.com/transactions/injuries.html")
current<-links(start)
nextlink<-current[grep("?yr=",current)]
nextlink<-nextlink[-grep("/standings/",nextlink)]
nextlink<-nextlink[-grep("/draft/",nextlink)]
nextlink<-nextlink[-grep("/scores/",nextlink)]
nextlink
page<-"https://www.footballdb.com"
data<-NULL
l<-1
goto<-paste0(page, nextlink[l])
goto
URL<-read_html(goto)
divtables<-html_nodes(URL, "divtable")
divtables<-html_nodes(URL, ".divtable")
#Set the start web url
path1<-("https://www.footballdb.com/transactions/injuries.html?yr=")
seasons<-c("2016", "2017", "2020")
weeks<-1:17
data<-NULL
i<1
i<-1
j<-1
k<-1
path2<-paste0(path1,seasons[i])
path2
path3<-paste0(path2,"&wk=",j,"&type=reg")
path3
URL<-read_html(path3)
divtables<-html_nodes(URL, ".divtable")
temp<-html_text(divtables[k])
temp
temp<-data.table(temp)
View(temp)
tmep
temp
library(rvest)
library(XML)
library(data.table)
#this function is useful for grabbing all links on a page
links <- function(URL)
{
getLinks <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "href"))
node
},
links = function() links)
}
h1 <- getLinks()
htmlTreeParse(URL, handlers = h1)
h1$links()
}
#function to return name of players
get_name<-function(url){
page<-read_html(url)
node<-html_nodes(page,".player-name")
player_name<-html_text(node)
player_name
}
#Set the start web url
path1<-("https://www.footballdb.com/transactions/injuries.html?yr=")
seasons<-c("2016", "2017", "2020")
weeks<-1:17
data<-NULL
i<-1
k<-1
j<-1
path2<-paste0(path1,seasons[i])
path3<-paste0(path2,"&wk=",j,"&type=reg")
path3
URL<-read_html(path3)
divtables<-html_nodes(URL, ".divtable")
View(divtables)
temp<-html_text(divtables[k])
temp
divtables
divtables[1]
URL
divtables<-html_nodes(URL, ".divtable")
tables<-html_table(divtables,fill = TRUE)
tables<-html_table(divtables[2],fill = TRUE)
